



其数据组织方式是数组加链表,链表的存在是为了解决Hash冲突。
散列的意思是不像数组一样，一个一个往后存储。它是依据数组长度对key的Hash值取余来确定地址。

扩容

```
public class HashMap<K, V> extends AbstractMap<K, V> implements Cloneable, Serializable {

    // HashMap的最小容量，必须是2的正整次幂
    private static final int MINIMUM_CAPACITY = 4;

    // HashMap的最大容量（2的三十次方），必须是2的正整次幂
    private static final int MAXIMUM_CAPACITY = 1 << 30;

    // 所有空Map都使用这个空table，
    private static final Entry[] EMPTY_TABLE
            = new HashMapEntry[MINIMUM_CAPACITY >>> 1];
    // 加载因子
    static final float DEFAULT_LOAD_FACTOR = .75F;

    transient HashMapEntry<K, V>[] table;

    transient HashMapEntry<K, V> entryForNullKey;

    transient int size;

    transient int modCount;

    //  阈值，用于判断是否要扩容。默认值是.75 * capacity
    // 比如capacity是100，那这个阈值就是75
    // 也就是说，HashMap装了75个数据之后，就扩容。
    // 此时table被使用了应该是小于等于 75
    private transient int threshold;

    // Views - lazily initialized
    private transient Set<K> keySet;
    private transient Set<Entry<K, V>> entrySet;
    private transient Collection<V> values;

// 数据结构
// 这个Entry是单向链表，也就是发生冲突之后的那个链表。
    static class HashMapEntry<K, V> implements Entry<K, V> {
        final K key;
        V value;
        final int hash;
        HashMapEntry<K, V> next;

        HashMapEntry(K key, V value, int hash, HashMapEntry<K, V> next) {
            this.key = key;
            this.value = value;
            this.hash = hash;
            this.next = next;
        }

        public final K getKey() {
            return key;
        }

        public final V getValue() {
            return value;
        }

        public final V setValue(V value) {
            V oldValue = this.value;
            this.value = value;
            return oldValue;
        }

        @Override public final boolean equals(Object o) {
            if (!(o instanceof Entry)) {
                return false;
            }
            Entry<?, ?> e = (Entry<?, ?>) o;
            return Objects.equal(e.getKey(), key)
                    && Objects.equal(e.getValue(), value);
        }

        @Override public final int hashCode() {
            return (key == null ? 0 : key.hashCode()) ^
                    (value == null ? 0 : value.hashCode());
        }

        @Override public final String toString() {
            return key + "=" + value;
        }
    }

    //  构造函数，构造一个空的HashMap
    @SuppressWarnings("unchecked")
    public HashMap() {
        table = (HashMapEntry<K, V>[]) EMPTY_TABLE;
        // 第一次put数据的时候，强迫替代这个空table
        threshold = -1; // Forces first put invocation to replace EMPTY_TABLE
    }
// 指定容量的构造函数
    public HashMap(int capacity) {
        if (capacity < 0) {
            throw new IllegalArgumentException("Capacity: " + capacity);
        }

        if (capacity == 0) {
          // 如果容量为0，构造一个空的HashMap
            @SuppressWarnings("unchecked")
            HashMapEntry<K, V>[] tab = (HashMapEntry<K, V>[]) EMPTY_TABLE;
            table = tab;
            threshold = -1; // Forces first put() to replace EMPTY_TABLE
            return;
        }
//      容量不能越界，且必须为2的整次幂
        if (capacity < MINIMUM_CAPACITY) {
            capacity = MINIMUM_CAPACITY;
        } else if (capacity > MAXIMUM_CAPACITY) {
            capacity = MAXIMUM_CAPACITY;
        } else {
            capacity = Collections.roundUpToPowerOfTwo(capacity);
        }
        makeTable(capacity);
    }

// 指定容量和加载因子，但是指定也白指定，因为忽略了loadFactor
// 也就是加载因子永远都是0.75，这样做简化了代码，提高了程序性能。
    public HashMap(int capacity, float loadFactor) {
        this(capacity);

        if (loadFactor <= 0 || Float.isNaN(loadFactor)) {
            throw new IllegalArgumentException("Load factor: " + loadFactor);
        }

    }

    static int capacityForInitSize(int size) {
        int result = (size >> 1) + size; // Multiply by 3/2 to allow for growth

        // boolean expr is equivalent to result >= 0 && result<MAXIMUM_CAPACITY
        return (result & ~(MAXIMUM_CAPACITY-1))==0 ? result : MAXIMUM_CAPACITY;
    }


    @Override public V put(K key, V value) {
        if (key == null) {
            return putValueForNullKey(value);
        }
//      算出key的Hash值，然后把这个值用table长度减一取余得出索引
//      容量必须是2的幂次方是有原因的，这样就可以将取余%运算变成与 & 运算了
        int hash = Collections.secondaryHash(key);
        HashMapEntry<K, V>[] tab = table;
        int index = hash & (tab.length - 1);
        // 这个位置有可能因为冲突存在单链表，所以需要对单链表索引
        // 如果key相同，就换掉它的value。
        // 如果遍历结束没有相同的key，就执行插入操作，也就是addNewEntry。
        for (HashMapEntry<K, V> e = tab[index]; e != null; e = e.next) {
            if (e.hash == hash && key.equals(e.key)) {
                preModify(e);
                V oldValue = e.value;
                e.value = value;
                return oldValue;
            }
        }

        // No entry for (non-null) key is present; create one
        modCount++;
        if (size++ > threshold) {
            tab = doubleCapacity();
            index = hash & (tab.length - 1);
        }
        // 插入一个Entry，实际上是插入在了单链表的表头。
        addNewEntry(key, value, hash, index);
        return null;
    }

    private V putValueForNullKey(V value) {
        HashMapEntry<K, V> entry = entryForNullKey;
        if (entry == null) {
            addNewEntryForNullKey(value);
            size++;
            modCount++;
            return null;
        } else {
            preModify(entry);
            V oldValue = entry.value;
            entry.value = value;
            return oldValue;
        }
    }

  /**
  HashMapEntry的构造方法
     HashMapEntry(K key, V value, int hash, HashMapEntry<K, V> next) {
         this.key = key;
         this.value = value;
         this.hash = hash;
         this.next = next;
     }
     */
    // 这样的话，是插入在链表首部
    // 即便是当前数组那里存在数据，也可以加入，解决了冲突。
    void addNewEntry(K key, V value, int hash, int index) {
        table[index] = new HashMapEntry<K, V>(key, value, hash, table[index]);
    }

// 通过key去查找value
    public V get(Object key) {
        if (key == null) {
            HashMapEntry<K, V> e = entryForNullKey;
            return e == null ? null : e.value;
        }

        int hash = Collections.secondaryHash(key);
        HashMapEntry<K, V>[] tab = table;
        for (HashMapEntry<K, V> e = tab[hash & (tab.length - 1)];e != null; e = e.next) {
            K eKey = e.key;
            // 如果key的地址相同，或者hash相同。
            // 疑问 hash对比和equals有什么区别?
            if (eKey == key || (e.hash == hash && key.equals(eKey))) {
                return e.value;
            }
        }
        return null;
    }



    /**
     * Doubles the capacity of the hash table. Existing entries are placed in
     * the correct bucket on the enlarged table. If the current capacity is,
     * MAXIMUM_CAPACITY, this method is a no-op. Returns the table, which
     * will be new unless we were already at MAXIMUM_CAPACITY.
     */
    //  容量扩大2倍
    private HashMapEntry<K, V>[] doubleCapacity() {
        HashMapEntry<K, V>[] oldTable = table;
        int oldCapacity = oldTable.length;
        if (oldCapacity == MAXIMUM_CAPACITY) {
            return oldTable;
        }
        // 创建一个容量翻倍的table
        int newCapacity = oldCapacity * 2;
        HashMapEntry<K, V>[] newTable = makeTable(newCapacity);
        if (size == 0) {
            return newTable;
        }

        for (int j = 0; j < oldCapacity; j++) {
            /*
             * Rehash the bucket using the minimum number of field writes.
             * This is the most subtle and delicate code in the class.
             */
            //  注释说，接下来的一段代码是整个类的精华
            HashMapEntry<K, V> e = oldTable[j];
            if (e == null) {
                continue;
            }
            // 原来的索引
            int highBit = e.hash & oldCapacity;
            HashMapEntry<K, V> broken = null;
            newTable[j | highBit] = e;
            for (HashMapEntry<K, V> n = e.next; n != null; e = n, n = n.next) {
                int nextHighBit = n.hash & oldCapacity;
                if (nextHighBit != highBit) {
                    if (broken == null)
                        newTable[j | nextHighBit] = n;
                    else
                        broken.next = n;
                    broken = e;
                    highBit = nextHighBit;
                }
            }
            if (broken != null)
                broken.next = null;
        }
        return newTable;
    }


    /**
     * Creates a new entry for the null key, and the given value and
     * inserts it into the hash table. This method is called by put
     * (and indirectly, putAll), and overridden by LinkedHashMap.
     */
    void addNewEntryForNullKey(V value) {
        entryForNullKey = new HashMapEntry<K, V>(null, value, 0, null);
    }

    /**
     * Like newEntry, but does not perform any activity that would be
     * unnecessary or inappropriate for constructors. In this class, the
     * two methods behave identically; in LinkedHashMap, they differ.
     */
    HashMapEntry<K, V> constructorNewEntry(
            K key, V value, int hash, HashMapEntry<K, V> first) {
        return new HashMapEntry<K, V>(key, value, hash, first);
    }

    /**
     * Copies all the mappings in the specified map to this map. These mappings
     * will replace all mappings that this map had for any of the keys currently
     * in the given map.
     *
     * @param map
     *            the map to copy mappings from.
     */
    @Override public void putAll(Map<? extends K, ? extends V> map) {
        ensureCapacity(map.size());
        super.putAll(map);
    }


    //  这个方法只被 putAll调用了，
    // 它的容量不是翻倍，而是扩大到刚好装下newmap的2的整次幂
    private void ensureCapacity(int numMappings) {
        int newCapacity = Collections.roundUpToPowerOfTwo(capacityForInitSize(numMappings));
        HashMapEntry<K, V>[] oldTable = table;
        int oldCapacity = oldTable.length;
        if (newCapacity <= oldCapacity) {
            return;
        }
        if (newCapacity == oldCapacity * 2) {
            doubleCapacity();
            return;
        }

        // We're growing by at least 4x, rehash in the obvious way
        HashMapEntry<K, V>[] newTable = makeTable(newCapacity);
        if (size != 0) {
            int newMask = newCapacity - 1;
            for (int i = 0; i < oldCapacity; i++) {
                for (HashMapEntry<K, V> e = oldTable[i]; e != null;) {
                    HashMapEntry<K, V> oldNext = e.next;
                    int newIndex = e.hash & newMask;
                    HashMapEntry<K, V> newNext = newTable[newIndex];
                    newTable[newIndex] = e;
                    e.next = newNext;
                    e = oldNext;
                }
            }
        }
    }


    private HashMapEntry<K, V>[] makeTable(int newCapacity) {
        @SuppressWarnings("unchecked") HashMapEntry<K, V>[] newTable
                = (HashMapEntry<K, V>[]) new HashMapEntry[newCapacity];
        table = newTable;
        threshold = (newCapacity >> 1) + (newCapacity >> 2); // 3/4 capacity
        return newTable;
    }

    @Override public V remove(Object key) {
        if (key == null) {
            return removeNullKey();
        }
        int hash = Collections.secondaryHash(key);
        HashMapEntry<K, V>[] tab = table;
        int index = hash & (tab.length - 1);
        for (HashMapEntry<K, V> e = tab[index], prev = null;
                e != null; prev = e, e = e.next) {
            if (e.hash == hash && key.equals(e.key)) {
                if (prev == null) {
                    tab[index] = e.next;
                } else {
                    prev.next = e.next;
                }
                modCount++;
                size--;
                postRemove(e);
                return e.value;
            }
        }
        return null;
    }

    private V removeNullKey() {
        HashMapEntry<K, V> e = entryForNullKey;
        if (e == null) {
            return null;
        }
        entryForNullKey = null;
        modCount++;
        size--;
        postRemove(e);
        return e.value;
    }

    //  把table里都装上null
    @Override public void clear() {
        if (size != 0) {
            Arrays.fill(table, null);
            entryForNullKey = null;
            modCount++;
            size = 0;
        }
    }

}

```



## put方法
```
public V put(K key, V value) {
    // 处理key为null，HashMap允许key和value为null
    if (key == null)
        return putForNullKey(value);
    // 得到key的哈希码
    int hash = hash(key);
    // 通过哈希码计算出bucketIndex  这个值是用 table.length-1对hash码取余
    // 这样得到的结果一定在 0-table.length-1之间，从而不会越界
    int i = indexFor(hash, table.length);
    // 取出bucketIndex位置上的元素，并循环单链表，判断key是否已存在
    for (Entry<K,V> e = table[i]; e != null; e = e.next) {
        Object k;
        // 哈希码相同并且对象相同时
        if (e.hash == hash && ((k = e.key) == key || key.equals(k))) {
            // 新值替换旧值，并返回旧值
            V oldValue = e.value;
            e.value = value;
            e.recordAccess(this);
            return oldValue;
        }
    }

    // key不存在时，加入新元素
    modCount++;
    addEntry(hash, key, value, i);
    return null;
}
```
HashMap在存储的时候，冲突一定时常发生。
因为Entry[]的长度很短

容量必须是2的幂次方是有原因的，这样就可以将取余运算变成 & 运算了
当容量一定是2^n时，h & (length - 1) == h % length，它俩是等价不等效的，
位运算效率非常高，实际开发中，很多的数值运算以及逻辑判断都可以转换成位运算，
但是位运算通常是难以理解的，因为其本身就是给电脑运算的，运算的是二进制，而不是给人类运算的，
人类运算的是十进制，这也是位运算在普遍的开发者中间不太流行的原因(门槛太高)。
这个等式实际上可以推理出来，2^n转换成二进制就是1+n个0，
减1之后就是0+n个1，如16 -> 10000，15 -> 01111，那根据&位运算的规则，
都为1(真)时，才为1，那0≤运算后的结果≤15，假设h <= 15，那么运算后的结果就是h本身，h >15，
运算后的结果就是最后三位二进制做&运算后的值，最终，就是%运算后的余数，我想，这就是容量必须为2的幂的原因。
